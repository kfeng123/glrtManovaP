\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}
\modulolinenumbers[5]

\journal{Journal of \LaTeX\ Templates}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xeCJK}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}


\DeclareMathOperator{\mytr}{tr}
\DeclareMathOperator{\mydiag}{diag}
\DeclareMathOperator{\myrank}{Rank}
\DeclareMathOperator{\myE}{E}
\DeclareMathOperator{\myVar}{Var}


\theoremstyle{plain}
\newtheorem{theorem}{\quad\quad Theorem}
\newtheorem{proposition}{\quad\quad Proposition}
\newtheorem{corollary}{\quad\quad Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{assumption}{\quad\quad Assumption}
\newtheorem{condition}{Condition}

\theoremstyle{definition}
\newtheorem{remark}{\quad\quad Remark}
\theoremstyle{remark}


\begin{document}

\begin{frontmatter}

\title{Elsevier \LaTeX\ template\tnoteref{mytitlenote}}
\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}

%% Group authors per affiliation:
\author{Elsevier\fnref{myfootnote}}
\address{Radarweg 29, Amsterdam}
\fntext[myfootnote]{Since 1880.}

%% or include affiliations in footnotes:
\author[mymainaddress,mysecondaryaddress]{Elsevier Inc}
\ead[url]{www.elsevier.com}

\author[mysecondaryaddress]{Global Customer Service\corref{mycorrespondingauthor}}
\cortext[mycorrespondingauthor]{Corresponding author}
\ead{support@elsevier.com}

\address[mymainaddress]{1600 John F Kennedy Boulevard, Philadelphia}
\address[mysecondaryaddress]{360 Park Avenue South, New York}

\begin{abstract}
This template helps you to create a properly formatted \LaTeX\ manuscript.
\end{abstract}

\begin{keyword}
\texttt{elsarticle.cls}\sep \LaTeX\sep Elsevier \sep template
\MSC[2010] 00-01\sep  99-00
\end{keyword}

\end{frontmatter}

\linenumbers
\section{GLRT}
Suppose $\{X_{i1},\ldots, X_{in_i}\}$ are i.i.d.\ distributed as $N(\mu_i,\Sigma)$ for $1\leq i\leq K$.
Let $\mathbf{X}_i=(X_{i1},\ldots,X_{in_i})$ for $i=1,\ldots,k$.
The $k$ samples are independent.
$\mu_i$, $i=1\ldots, k$ and $\Sigma>0$ are unknown. An interesting problem in multivariate analysis is to test the hypotheses
\begin{equation}
    H: \mu_1=\mu_2=\cdots=\mu_k\quad v.s.\quad K: \textrm{$\mu_i\neq \mu_j$ for some $i\neq j$}.
\end{equation}
Let $\mathbf{Z}=(X_1,\ldots,X_k)$.
$$
f(Z;\mu_1,\ldots,\mu_k,\Sigma)=\prod_{i=1}^k\Big[
    (2\pi)^{-n_i p/2}|\Sigma|^{-n_i/2}\exp(-\frac{1}{2}\mathrm{tr}\Sigma^{-1}\sum_{j=1}^{n_i}(x_{ij}-\mu_i)(x_{ij}-\mu_i)^T)
    \Big].
$$
Assume $n=\sum_{i=1}^p n_i<p$. Let $a\in \mathbb{R}^p$ be a vector satisfying $a^T a=1$. Then
$$
f_a(a^T Z;\mu_1,\ldots,\mu_k,\Sigma)=
    (2\pi)^{-n/2}|a^T \Sigma a|^{-n/2}\exp\Big(-\frac{1}{2 a^T \Sigma a}\sum_{i=1}^k\sum_{j=1}^{n_i}(a^Tx_{ij}-a^T\mu_i)^2\Big)
$$
\begin{equation}
    \begin{aligned}
        \max_{\mu_1,\ldots,\mu_k,\Sigma}f_a(a^T Z,\mu_1,\ldots,\mu_k,\Sigma)
        =
        (2\pi)^{-n/2}\big(\sum_{i=1}^k\sum_{j=1}^{n_i}(a^Tx_{ij}-a^T\bar{\mathbf{X}}_i)^2\big)^{-n/2}e^{-{n}/{2}}
    \end{aligned}
\end{equation}

Let $S_i=\sum_{j=1}^{n_i}(x_{ij}-\bar{\mathbf{X}}_i)(x_{ij}-\bar{\mathbf{X}}_i)^T$ and $S=\sum_{i=1}^k S_i$.


Under $H$, we have
\begin{equation}
    \begin{aligned}
        \max_{\mu,\Sigma}f_a(a^T Z,\mu,\ldots,\mu,\Sigma)
        =
        (2\pi)^{-n/2}\big(\sum_{i=1}^k\sum_{j=1}^{n_i}(a^Tx_{ij}-a^T\bar{\mathbf{X}})^2\big)^{-n/2}e^{-{n}/{2}}
    \end{aligned}
\end{equation}

The generalized likelihood ratio test statistic is defined as
\begin{equation}
    \begin{aligned}
        T(Z)
        =
        \max_{a^T a=1, a^T S a=0} 
        a^T \sum_{i=1}^k n_i (\bar{\mathbf{X}}_i-\bar{\mathbf{X}})(\bar{\mathbf{X}}_i-\bar{\mathbf{X}})^T a
    \end{aligned}
\end{equation}
Let $J=\mathrm{diag}(n_1^{-1/2}\mathbf{1}_{n_1},\ldots,n_k^{-1/2}\mathbf{1}_{n_k})$.
Then $S=Z(I_n-JJ^T)Z^T$ and
\begin{equation}
    \begin{aligned}
        \sum_{i=1}^k n_i (\bar{\mathbf{X}}_i-\bar{\mathbf{X}})(\bar{\mathbf{X}}_i-\bar{\mathbf{X}})^T 
        =Z(JJ^T-\frac{1}{n}\mathbf{1}_n\mathbf{1}_n^T)Z^T.
    \end{aligned}
\end{equation}
The matrix $I_n-JJ^T$, $JJ^T-\frac{1}{n}\mathbf{1}_n\mathbf{1}_n^T$ and $\frac{1}{n}\mathbf{1}_n\mathbf{1}_n^T$ are all projection matrix and pairwise orthogonal with rank $n-k$, $k-1$ and $1$.

Let $\tilde{J}$ be a $n\times (n-k)$ matrix satisfied $\tilde{J}\tilde{J}^T =I-JJ^T$.
Then $S=Z\tilde{J}\tilde{J}^T Z^T$ and
 Note that 
$$
Z(JJ^T-\frac{1}{n}\mathbf{1}_n\mathbf{1}_n^T)Z^T
=ZJ(I_k-\frac{1}{n}J^T\mathbf{1}_n \mathbf{1}_n^T J)J^T Z^T.
$$
Note that $I_k-\frac{1}{n}J^T\mathbf{1}_n \mathbf{1}_n^T J$ is a projection matrix with rank $k-1$.
Let $C$ be a $k\times (k-1)$ matrix satisfied $CC^T=I_k-\frac{1}{n}J^T\mathbf{1}_n \mathbf{1}_n^T J$.

In Proposition~\ref{optProp}, letting $A=Z\tilde{J}$ and $B=ZJ C C^T J^TZ^T$ yields 
$$
\begin{aligned}
    T(Z)&=\lambda_{max}\big((I_p-
    Z\tilde{J}{(\tilde{J}^T Z^T Z\tilde{J})}^{-1}\tilde{J}^T Z^T
    )ZJCC^TJ^TZ^T (I_p-
    Z\tilde{J}{(\tilde{J}^T Z^T Z\tilde{J})}^{-1}\tilde{J}^T Z^T
    )\big)
\\
    &=\lambda_{max}\big(C^TJ^TZ^T (I_p-
    Z\tilde{J}{(\tilde{J}^T Z^T Z\tilde{J})}^{-1}\tilde{J}^T Z^T
    )ZJC\big).
\end{aligned}
$$
%where $H_A=Z\tilde{J}{(\tilde{J}^T Z^T Z\tilde{J})}^{-1}\tilde{J}^T Z^T$.
Note that
\begin{equation}
    \begin{aligned}
        &\Big(
        \begin{pmatrix}
            J^T\\
            \tilde{J}^T
        \end{pmatrix}
        Z^T Z
        \begin{pmatrix}
            J&\tilde{J}
        \end{pmatrix}
        \Big)^{-1}\\
        &=
        \begin{pmatrix}
            J^T Z^T ZJ & J^T Z^T Z\tilde{J}\\
            \tilde{J}^T Z^T ZJ & \tilde{J}^T Z^T Z \tilde{J}
        \end{pmatrix}^{-1}
        &=
        \begin{pmatrix}
            J^T {(Z^T Z)}^{-1}J & J^T {(Z^T Z)}^{-1}\tilde{J}\\
            \tilde{J}^T {(Z^T Z)}^{-1}J & \tilde{J}^T {(Z^T Z)}^{-1} \tilde{J}
        \end{pmatrix}.
    \end{aligned}
\end{equation}
It follows that
\begin{equation}
    \begin{aligned}
        &{\big( J^T {(Z^T Z)}^{-1}J \big)}^{-1}\\
        =&J^T Z^T ZJ - J^T Z^T Z\tilde{J}{(\tilde{J}^T Z^T Z \tilde{J})}^{-1}
            \tilde{J}^T Z^T ZJ \\
        =& J^T Z^T( I_p- Z\tilde{J}{(\tilde{J}^T Z^T Z \tilde{J})}^{-1}
            \tilde{J}^T Z^T) ZJ 
    \end{aligned}
\end{equation}
It follows that
\begin{equation}
    \begin{aligned}
        T(Z)=
        \lambda_{\max}\Big(C^T{\big( J^T {(Z^T Z)}^{-1}J \big)}^{-1}C\Big)\\
    \end{aligned}
\end{equation}
\begin{proposition}\label{optProp}
    Suppose $A$ is a $p\times r$ matrix with rank $r$ and $B$ is a $p\times p$  non-zero semi-definite matrix.
    Let $H_A=A{(A^TA)}^{-1}A^T$.
    Then
    \begin{equation}
        \max_{a^T a=1, a^T A A^T a=0}a^T B a=
        \lambda_{\max}\big((I_p-H_A)B(I_p-H_A)\big).
    \end{equation}
\end{proposition}
\begin{proof}
    Note that $a^T A A^T a=0$ is equivalent to $A^T a=0$ and is in turn equivalent to $H_A a=0$.
    In this circumstance, $a= (I_p-H_A)a$.
    Then
    \begin{equation}\label{eq:prop1eq1}
        \begin{aligned}
        \max_{a^T a=1, a^T A A^T a=0}a^T B a
            &=
            \max_{a^T a=1, H_A a=0}a^T B a\\
            &=
        \max_{a^T a=1, H_A a=0}a^T(I_p-H_A) B (I_p-H_A)a.
        \end{aligned}
    \end{equation}
    It's obvious that $\eqref{eq:prop1eq1}\leq\lambda_{\max}\big((I-H_A)B(I-H_A)\big)$.
    On the other hand, let $\alpha_1$ be one eigenvector corresponding to the largest eigenvalue of $(I-H_A)B(I-H_A)$.
    Note that the row of $H_A$ are all eigenvetors of $(I-H_A)B(I-H_A)$ corresponding to eigenvalue $0$. It follows that $H_A\alpha_1=0$. Now that $\alpha_1$ satisfies the constraint of~\eqref{eq:prop1eq1},~\eqref{eq:prop1eq1} is maximized when $a=\alpha_1$.
    
\end{proof}

\section{Schott's method}

$$
E=ZZ^T-\sum_{i=1}^k n_i \bar{X}_i \bar{X}_i^T.
$$

$$
H=\sum_{i=1}^{k} n_i \bar{X}_i \bar{X}_i^T - n\bar{X}\bar{X}^T.
$$

$$
\mytr E = \mytr Z^T Z - \mytr J^T Z^T Z J.
$$


$$
\mytr H = \mytr J^T Z^T Z J - \frac{1}{n} 1_n^T Z^T Z 1_n
$$

$$
T_{SC}=\frac{1}{\sqrt{n-1}}(
\frac{1}{k-1}\mytr H-\frac{1}{n-k} \mytr E
)
$$


\section{Theory}
Let $\Sigma= U\Lambda U^T$ be the eigenvalue decomposition of $\Sigma$, where $\Lambda =\mydiag (\lambda_1,\ldots,\lambda_p)$.
Let $U=(U_1,U_2)$ where $U_1$ is $p\times r$ and $U_2$ is $p\times (p-r)$. Let $\Lambda_1=\mydiag(\lambda_1,\ldots,\lambda_r)$ and $\Lambda_2=\mydiag(\lambda_{r+1},\ldots,\lambda_p)$.
Then $\Sigma=U_1\Lambda_1 U_1^T+U_2\Lambda_2 U_2^T$.

Let $Z\tilde{J}=U_{Z\tilde{J}}D_{Z\tilde{J}}V_{Z\tilde{J}}^T$ be the singular value decomposition of $Z\tilde{J}$. Let $H_{Z\tilde{J}}=U_{Z\tilde{J}}U_{Z\tilde{J}}^T$.
Then
$T(Z) = \lambda_{\max}(C^T J^T Z^T (I_p-H_{Z\tilde{J}})ZJC)$.
Note that
$$
\myE (ZJC) =(\sqrt{n_1}\mu_1,\ldots,\sqrt{n_k}\mu_k) C\overset{def}{=}\mu_{f}.
$$


\begin{assumption}\label{assumpEigen}
    Assume $C \geq \lambda_{r+1} \geq \ldots \geq \lambda_{p} \geq c$, where $c$ and $C$ are absolute constant.
\end{assumption}







\begin{theorem}\label{thm1}
    Suppose Assumption~\eqref{assumpEigen} holds. Suppose 
    \begin{equation}
    p/n\to \infty,\quad\textrm{and}\quad \frac{\lambda_1^2 p}{\lambda_r^2 n^2}\to 0.
    \end{equation}
    Suppose
    \begin{equation}
        \frac{\lambda_r n}{p}\to \infty.
    \end{equation}
    Suppose
    \begin{equation}
        \frac{1}{\sqrt{p}}\|\mu_f\|_F^2=O(1).
    \end{equation}
    Then
    \begin{equation}
        (\mytr \Lambda_2^2)^{-1/2}\big( C^TJ^T Z^T(I_p-H_{Z\tilde J}) ZJC-(\mytr \Lambda_2) I_{k-1} -\mu_f^T(I_p-H_{Z\tilde Z})\mu_f\big)\xrightarrow{\mathcal{L}} W_{k-1},
    \end{equation}
where $W_{k-1}$ is a $(k-1)\times(k-1)$ symmetric random matrix whose entries above the main diagonal are i.i.d.\ $N(0,1)$ and the entries on the diagonal are i.i.d.\ $N(0,2)$.
\end{theorem}

\section{Simulation Results}

$$
SNR=\frac{\|\mu_f\|_F^2}{\sqrt{\mytr (\Sigma^2)}}
$$
\begin{table}[!hbp]
    \caption[short]{$n_1=n_2=n_3=10$, non-sparse, $\Sigma=\mydiag()$}
    \centering
    \begin{tabular}{*{10}{c}}
    \toprule
    \multirow{2}{*}{SNR} &\multicolumn{3}{c}{$p=50$}&\multicolumn{3}{c}{$p=75$}&\multicolumn{3}{c}{$p=100$} \\
        \cmidrule(r){2-4}\cmidrule(r){5-7}\cmidrule(r){8-10}
        &SC & CX & NEW& SC & CX & NEW &SC & CX & NEW\\
    \midrule
        0& 2.000&3.000&4.000&5.000&6.000&7.000&8.000&9.000&10.000\\
    0.1\\
    0.2\\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[!hbp]
    \caption[short]{$n_1=n_2=n_3=25$, non-sparse}
    \centering
    \begin{tabular}{*{10}{c}}
    \toprule
    \multirow{2}{*}{SNR} &\multicolumn{3}{c}{$p=100$}&\multicolumn{3}{c}{$p=150$}&\multicolumn{3}{c}{$p=200$} \\
        \cmidrule(r){2-4}\cmidrule(r){5-7}\cmidrule(r){8-10}
        &SC & CX & NEW& SC & CX & NEW &SC & CX & NEW\\
    \midrule
        0& 2.000&3.000&4.000&5.000&6.000&7.000&8.000&9.000&10.000\\
    0.1\\
    0.2\\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[!hbp]
    \caption[short]{$n_1=n_2=n_3=10$, sparse}
    \centering
    \begin{tabular}{*{10}{c}}
    \toprule
    \multirow{2}{*}{SNR} &\multicolumn{3}{c}{$p=50$}&\multicolumn{3}{c}{$p=75$}&\multicolumn{3}{c}{$p=100$} \\
        \cmidrule(r){2-4}\cmidrule(r){5-7}\cmidrule(r){8-10}
        &SC & CX & NEW& SC & CX & NEW &SC & CX & NEW\\
    \midrule
        0& 2.000&3.000&4.000&5.000&6.000&7.000&8.000&9.000&10.000\\
    0.1\\
    0.2\\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[!hbp]
    \caption[short]{$n_1=n_2=n_3=25$, sparse}
\begin{center}
    \begin{tabular}{*{10}{c}}
    \toprule
    \multirow{2}{*}{SNR} &\multicolumn{3}{c}{$p=100$}&\multicolumn{3}{c}{$p=150$}&\multicolumn{3}{c}{$p=200$} \\
        \cmidrule(r){2-4}\cmidrule(r){5-7}\cmidrule(r){8-10}
        &SC & CX & NEW& SC & CX & NEW &SC & CX & NEW\\
    \midrule
        0& 2.000&3.000&4.000&5.000&6.000&7.000&8.000&9.000&10.000\\
    0.1\\
    0.2\\
    \bottomrule
\end{tabular}
\end{center}
\end{table}

\section{Appendix}

\begin{proof}[\textrm{Proof of Theorem~\ref{thm1}}]
It can be seen that $ZJC$ is independent of ${Z\tilde{J}}$.
Since
$
\myE (Z\tilde{J}) = O_{p\times (n-k)}
$,
we can write
$
Z\tilde{J} = U\Lambda^{1/2} G_1
$,
where $G_1$ is a $p\times (n-k)$ matrix with i.i.d.\ $N(0,1)$ entries.
We write
$
ZJC = \mu_f + U\Lambda^{1/2} G_2
$, 
where $G_2$ is a $p\times (k-1)$ matrix with i.i.d. $N(0,1)$ entries.

Then 
\begin{equation}\label{eq:maindec}
\begin{aligned}
C^TJ^T Z^T(I_p-H_{Z\tilde J}) ZJC
    =&
    G_2^T \Lambda^{1/2}U^T (I_P-H_{Z\tilde{J}})U\Lambda_{1/2}G_2+
\mu_f^T (I_p -H_{Z\tilde{J}})\mu_f+\\
    &\mu_f^T (I_p -H_{Z\tilde{J}})U\Lambda^{1/2}G_2+
G_2^T \Lambda^{1/2}U^T (I_P-H_{Z\tilde{J}})\mu_f.
\end{aligned}
\end{equation}
To deal the first term, we note that
$$
    G_2^T \Lambda^{1/2}U^T (I_p-H_{Z\tilde{J}})U\Lambda_{1/2}G_2\sim
    \sum_{i=1}^p \lambda_i (\Lambda^{1/2}U^T (I_p-H_{Z\tilde{J}})U\Lambda^{1/2})\xi_i \xi_i^T,
$$
where $\xi_i\overset{i.i.d.}{\sim} N(0,I_{k-1})$. The key to its asymptotic behavior is the positive eigenvalues of $\Lambda^{1/2}U^T (I_p-H_{Z\tilde{J}})U\Lambda^{1/2}$, which in turn equal to the eigenvalues of $(I_p-H_{Z\tilde{J}})U\Lambda U^T (I_p-H_{Z\tilde{J}})$.
Write $(I_p-H_{Z\tilde{J}})U\Lambda U^T (I_p-H_{Z\tilde{J}})$ as the sum of two terms
$$
\begin{aligned}
    &(I_p-H_{Z\tilde{J}})U\Lambda U^T (I_p-H_{Z\tilde{J}})
    \\
    =&
    (I_p-H_{Z\tilde{J}})U_1\Lambda_1 U_1^T(I_p-H_{Z\tilde{J}})+(I_p-H_{Z\tilde{J}})U_2\Lambda_2 U_2^T (I_p-H_{Z\tilde{J}})
    \overset{def}{=}R_1+R_2.
\end{aligned}
$$

Note that
$$
\begin{aligned}
    &\lambda_{\max}\big( R_1 \big)
    =
    \lambda_{\max}\big(\Lambda_1^{1/2} U_1^T(I_p-H_{Z\tilde{J}}) U_1 \Lambda_1^{1/2}\big)
    \leq 
    \lambda_{\max}\big(\Lambda_1^{1/2} U_1^T(I_p-U_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T) U_1 \Lambda_1^{1/2}\big)\\
    \leq &
    \lambda_1
    \lambda_{\max}\big(U_1^T(I_p-U_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T) U_1 \big)
    = 
    \lambda_1
    \lambda_{\max}\big(I_r - U_1^TU_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T U_1 \big).
\end{aligned}
$$

To investigate the behavior of $U_{Z\tilde{J}}$, we need to investigate the behavior of $D_{Z\tilde{J}}$ first.
Note that 
$
G_1^T \Lambda G_1 = \tilde{J}^T Z^T Z\tilde{J} = V_{Z\tilde{J}} D_{Z\tilde{J}}^2 V_{Z\tilde{J}}^T
$, and 
$
G_1^T \Lambda G_1=
G_{1[1:r,]}^T \Lambda_1 G_{1[1:r,]}+
G_{1[(r+1):p,]}^T \Lambda_2 G_{1[(r+1):p,]}
$. We have
$$
V_{Z\tilde{J}} D_{Z\tilde{J}}^2 V_{Z\tilde{J}}^T=
G_{1[1:r,]}^T \Lambda_1 G_{1[1:r,]}+
G_{1[(r+1):p,]}^T \Lambda_2 G_{1[(r+1):p,]}.
$$
For $i=1,\ldots, r$,
\begin{equation}\label{eq:DLower}
\begin{aligned}
    &\lambda_i(G_{1[1:r,]}^T \Lambda_1 G_{1[1:r,]})
    \geq
\lambda_i(G_{1[1:r,]}^T \mydiag(\lambda_i I_{i},O_{(r-i)\times(r-i)}) G_{1[1:r,]})
\\
    = &
    \lambda_i \lambda_i(G_{1[1:i,]}G_{1[1:i,]}^T)=\lambda_i n(1+o_P(1)),
\end{aligned}
\end{equation}
where the last equality holds since $n^{-1}G_{1[1:i,]}G_{1[1:i,]}^T\xrightarrow{P}I_i$ by law of large numbers.
On the other hand, for $i=1,\ldots, r$,
\begin{equation}\label{eq:DUpper}
\begin{aligned}
    &\lambda_i(G_{1[1:r,]}^T \Lambda_1 G_{1[1:r,]})
    \\
    =&\lambda_i\Big(
    G_{1[1:r,]}^T \big(
    \mydiag(\lambda_1,\ldots,\lambda_{i-1},O_{(r-i+1)\times(r-i+1)})+
    \mydiag(O_{(i-1)\times(i-1)},\lambda_i,\ldots,\lambda_r)
    \big)
    G_{1[1:r,]}
    \Big)\\
    \leq&
\lambda_1(G_{1[1:r,]}^T \mydiag(O_{(i-1)\times(i-1)},\lambda_i,\ldots,\lambda_r) G_{1[1:r,]})
    \leq
    \lambda_1(G_{1[1:r,]}^T \mydiag(O_{(i-1)\times(i-1)},\lambda_i I_{r-i+1}) G_{1[1:r,]})
\\
    = &
    \lambda_i \lambda_1(G_{1[i:r,]}G_{1[i:r,]}^T)=\lambda_i n(1+o_P(1))
\end{aligned}
\end{equation}
where the first inequality holds by Weyl's inequality. It follows from~\eqref{eq:DLower} and~\eqref{eq:DUpper} that 
    $\lambda_i(G_{1[1:r,]}^T \Lambda_1 G_{1[1:r,]})=\lambda_i n(1+o_P(1))$ for $i=1,\ldots, r$.

    Note that
$\lambda_{\max}(G_{1[(r+1):p,]}^T \Lambda_2 G_{1[(r+1):p,]})\leq C\lambda_{\max}(G_{1[(r+1):p,]}^T G_{1[(r+1):p,]})=O_P(p)$ by Bai-Yin's law.
By assumption $\lambda_r n/p\to \infty$, we can deduce that $D_{Z\tilde{J}[i,i]}^2=\lambda_i(G_1^T \Lambda G_1)=\lambda_i n(1+o_P(1))$, $i=1,\ldots, r$.

Now we are ready to investigate the behavior of $U_{Z\tilde{J}}$.
Since
$
U\Lambda^{1/2} G_1 G_1^T \Lambda^{1/2} U^T 
    =U_{Z\tilde{J}}D_{Z\tilde{J}}^2 U_{Z\tilde{J}}^T
$,
we have
$
G_1 G_1^T  
    =\Lambda^{-1/2} U^T U_{Z\tilde{J}}D_{Z\tilde{J}}^2 U_{Z\tilde{J}}^TU\Lambda^{-1/2}
$, which further indicates
$$
\begin{aligned}
    &G_{1[(r+1):p,]} G_{1[(r+1):p,]}^T  
    =\Lambda_{2}^{-1/2} U_{[,(r+1):p]}^T U_{Z\tilde{J}}D_{Z\tilde{J}}^2 U_{Z\tilde{J}}^T U_{[,(r+1):p]}\Lambda_{2}^{-1/2}\\
    \geq&
    \Lambda_{2}^{-1/2} U_{[,(r+1):p]}^T U_{Z\tilde{J}[,1:r]}D_{Z\tilde{J}[1:r,1:r]}^2 U_{Z\tilde{J}[,1:r]}^T U_{[,(r+1):p]}\Lambda_{2}^{-1/2}\\
    \geq&
    D_{Z\tilde{J}[r,r]}^2
    \Lambda_{2}^{-1/2} U_{[,(r+1):p]}^T U_{Z\tilde{J}[,1:r]} U_{Z\tilde{J}[,1:r]}^T U_{[,(r+1):p]}\Lambda_{2}^{-1/2}.
\end{aligned}
$$
Thus,
$$
\lambda_{\max}(U_{[,(r+1):p]}^T U_{Z\tilde{J}[,1:r]} U_{Z\tilde{J}[,1:r]}^T U_{[,(r+1):p]})\leq 
\frac{C}{D^2_{Z\tilde{J}[r,r]}} \lambda_{1}
    (G_{1[(r+1):p,]} G_{1[(r+1):p,]}^T)
=O_P(\frac{p}{\lambda_r n}).
$$

Note that we have the simple relationship
$$
\begin{aligned}
    &\lambda_{\max}(U_{[,(r+1):p]}^T U_{Z\tilde{J}[,1:r]} U_{Z\tilde{J}[,1:r]}^T U_{[,(r+1):p]})
=
\lambda_{\max}( U_{Z\tilde{J}[,1:r]}^T U_{[,(r+1):p]}U_{[,(r+1):p]}^T U_{Z\tilde{J}[,1:r]})\\
    =&
    \lambda_{\max}( U_{Z\tilde{J}[,1:r]}^T (I_p- U_1 U_1^T) U_{Z\tilde{J}[,1:r]})=
    \lambda_{\max}(I_r- U_{Z\tilde{J}[,1:r]}^T  U_1 U_1^T U_{Z\tilde{J}[,1:r]})\\
    =&
    1-\lambda_{\min}( U_{Z\tilde{J}[,1:r]}^T  U_1 U_1^T U_{Z\tilde{J}[,1:r]})
    =
    1-\lambda_{\min}(U_1^T U_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T U_1)\\
    =&
    \lambda_{\max}(I_r-U_1^T U_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T U_1).
\end{aligned}
$$
Therefore 
    $
    \lambda_{\max}(I_r-U_1^T U_{Z\tilde{J}[,1:r]}U_{Z\tilde{J}[,1:r]}^T U_1)
=O_P(\frac{ p}{\lambda_r n})
    $, and we can conclude
$\lambda_{\max}(R_1)=O_P(\frac{\lambda_1 p}{\lambda_r n})$.

We now deal with $R_1+R_2$.
For $i=1,\ldots, r$,
$$
\lambda_i(R_1+R_2)\leq
\lambda_1(R_1+R_2)\leq \lambda_1(R_1)+\lambda_1(R_2)\leq O_P(\frac{\lambda_1 p}{\lambda_r n}) + C.
$$
For $i=r+1,\ldots, p-r$,
$$
\begin{aligned}
    &\lambda_i(R_1+R_2)\leq \lambda_{i-r}(R_2)
    =
     \lambda_{i-r}\big( \Lambda_2^{1/2} U_2^T (I_p-H_{Z\tilde{J}})U_2\Lambda_2^{1/2}\big)
    \leq
    \lambda_{i-r}(\Lambda_2)
    =\lambda_i.
\end{aligned}
$$
On the other hand,
for $i=1,\ldots, p-r-n+k$,
$$
\begin{aligned}
    &\lambda_i(R_1+R_2)\geq \lambda_i(R_2)
    =
     \lambda_i\big( \Lambda_2^{1/2} U_2^T (I_p-H_{Z\tilde{J}})U_2\Lambda_2^{1/2}\big)\\
    =&
    \lambda_i\big( \Lambda_2- \Lambda_2^{1/2} U_2^T H_{Z\tilde{J}}U_2 \Lambda_2^{1/2}\big)
    \geq 
    \lambda_{i+n-k}.
\end{aligned}
$$
The last equality holds since $U_2^T H_{Z\tilde{J}}U_2$ is at most of rank $n-k$.

As a consequence of these bounds, we have
$$
    \sum_{i=1}^{p-r-n+k}\lambda_{i+n-k}^2\leq \mytr [(R_1+R_2)^2]\leq  r(O_P(\frac{\lambda_1 p}{\lambda_r n})+C)^2+\sum_{i=r+1}^{p-r}\lambda_i^2,
$$
or
$$
    | \mytr [(R_1+R_2)^2]-\sum_{i=r+1}^{p}\lambda_{i}^2|\leq 
\sum_{i=r+1}^{n-k}\lambda_{i}^2+
\sum_{i=p-r+1}^{p}\lambda_{i}^2
+
    r(O_P(\frac{\lambda_1 p}{\lambda_r n})+C)^2.
$$
Similarly,
$$
    | \mytr [(R_1+R_2)]-\sum_{i=r+1}^{p}\lambda_{i}|\leq 
\sum_{i=r+1}^{n-k}\lambda_{i}+
\sum_{i=p-r+1}^{p}\lambda_{i}
+
    r(O_P(\frac{\lambda_1 p}{\lambda_r n})+C).
$$
These, conbined with the assumptions, yield
$$
     \mytr [(R_1+R_2)^2]=(1+o_P(1))\sum_{i=r+1}^{p}\lambda_{i}^2,
$$
and
$$
     \mytr [(R_1+R_2)]=\sum_{i=r+1}^{p}\lambda_{i}+O(n)+O_P(\frac{\lambda_1 p}{\lambda_r n}).
$$

Now we have the Lyapunov condition
$$
\frac{\lambda_1[(R_1+R_2)^2]}{
    \mytr [(R_1+R_2)^2]
}
%\leq
%\frac{
    %\big( O_P(\frac{\lambda_1 p}{\lambda_r n})+C\big)^2
%}{\sum_{i=1}^{p-r-n+k}\lambda_{i+n-k}^2}
%\leq
%\frac{
    %\big( O_P(\frac{\lambda_1 p}{\lambda_r n})+C\big)^2
%}{c(p-r-n+k)}
=
\frac{
    \big( O_P(\frac{\lambda_1 p}{\lambda_r n})+C\big)^2
}{
(1+o_P(1))\sum_{i=r+1}^{p}\lambda_{i}^2
}
\xrightarrow{P} 0.
$$
Apply Lyapunov central limit theorem conditioning on $H_{Z\tilde{J}}$, we have
$$
\begin{aligned}
    \big(\mytr[(R_1+R_2)^2]\big)^{-1/2}
    \big( G_2^T \Lambda^{1/2}U^T (I_p-H_{Z\tilde{J}})U\Lambda_{1/2}G_2-\mytr(R_1+R_2) I_{k-1} \big)
    \xrightarrow{\mathcal{L}} W_{k-1}
\end{aligned}
$$
where $W_{k-1}$ is a $(k-1)\times(k-1)$ symmetric random matrix whose entries above the main diagonal are i.i.d.\ $N(0,1)$ and the entries on the diagonal are i.i.d.\ $N(0,2)$.
By Slutsky's theorem, we have
$$
\begin{aligned}
    \big(\sum_{i=r+1}^p \lambda_i^2\big)^{-1/2}
    \big( G_2^T \Lambda^{1/2}U^T (I_p-H_{Z\tilde{J}})U\Lambda_{1/2}G_2-(\sum_{i=r+1}^p \lambda_i)I_{k-1} \big)
    \xrightarrow{\mathcal{L}}W_{k-1}
\end{aligned}
$$


As for the cross term of~\eqref{eq:maindec}, we have
$$
    \begin{aligned}
        &\myE [\|\mu_f^T (I_p -H_{Z\tilde{J}})U\Lambda^{1/2}G_2\|_F^2|Z\tilde{J}]\\
        = &
        (k-1)\mytr(\mu_f^T (I_p -H_{Z\tilde{J}})U\Lambda U^T (I_p -H_{Z\tilde{J}})\mu_f)\\
        \leq &
        (k-1)\lambda_1\big((I_p -H_{Z\tilde{J}})U\Lambda U^T (I_p -H_{Z\tilde{J}})\big)\|\mu_f\|^2_F\\
        = &
        (k-1) O_P(\frac{\lambda_1 p}{\lambda_r n})  \|\mu_f\|^2_F\\
        = &
        (k-1) O_P(\frac{\lambda_1 \sqrt{p}}{\lambda_r n}) \sqrt{p}  \|\mu_f\|^2_F=o_P(p)
    \end{aligned}
$$
The last equality holds when we assume $\frac{1}{\sqrt{p}}\|\mu_f\|_F^2=O(1)$. Hence $\|\mu_f^T (I_p -H_{Z\tilde{J}})U\Lambda^{1/2}G_2\|_F^2=o_P(p)$.
This completes the proof of the theorem.

\end{proof}






\section*{References}

\bibliography{mybibfile}

\end{document}
